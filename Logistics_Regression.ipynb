{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using code from llSourcell/logistic_regression_newtons_method\n",
    "%matplotlib inline\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "from patsy import dmatrices\n",
    "import warnings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the seed\n",
    "np.random.seed(0);\n",
    "tol=1e-8 # convergence tolerance\n",
    "\n",
    "lam = None # l2-regularization\n",
    "#how long to train for? epoch?\n",
    "max_iter = 20 # maximum allowed iterations\n",
    "r = 0.95 # covariance between x and z\n",
    "n = 1000 # number of observations (size of dataset to generate) \n",
    "sigma = 1 # variance of noise - how spread out is the data?\n",
    "## model settings\n",
    "beta_x, beta_z, beta_v = -4, .9, 1 # true beta coefficients\n",
    "var_x, var_z, var_v = 1, 1, 4 # variances of inputs\n",
    "\n",
    "## the model specification you want to fit\n",
    "formula = 'y ~ x + z + v + np.exp(x) + I(v**2 + z)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Lab--------------\\ANACONDA\\envs\\iaml\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>x</th>\n",
       "      <th>z</th>\n",
       "      <th>v</th>\n",
       "      <th>np.exp(x)</th>\n",
       "      <th>I(v ** 2 + z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.611418</td>\n",
       "      <td>-1.566192</td>\n",
       "      <td>15.613483</td>\n",
       "      <td>0.199604</td>\n",
       "      <td>242.214667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.080909</td>\n",
       "      <td>0.085959</td>\n",
       "      <td>42.720111</td>\n",
       "      <td>0.922278</td>\n",
       "      <td>1825.093814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297531</td>\n",
       "      <td>0.142110</td>\n",
       "      <td>3.530885</td>\n",
       "      <td>1.346531</td>\n",
       "      <td>12.609259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.412771</td>\n",
       "      <td>1.734809</td>\n",
       "      <td>-57.235945</td>\n",
       "      <td>4.107323</td>\n",
       "      <td>3277.688187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.204214</td>\n",
       "      <td>-0.302335</td>\n",
       "      <td>-0.074792</td>\n",
       "      <td>1.226561</td>\n",
       "      <td>-0.296741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.515413</td>\n",
       "      <td>2.075660</td>\n",
       "      <td>-74.190590</td>\n",
       "      <td>4.551301</td>\n",
       "      <td>5506.319245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.122694</td>\n",
       "      <td>-1.001452</td>\n",
       "      <td>-115.449743</td>\n",
       "      <td>0.325402</td>\n",
       "      <td>13327.641761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.490410</td>\n",
       "      <td>1.406678</td>\n",
       "      <td>203.717128</td>\n",
       "      <td>4.438913</td>\n",
       "      <td>41502.075078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.076719</td>\n",
       "      <td>0.961474</td>\n",
       "      <td>18.996406</td>\n",
       "      <td>2.935033</td>\n",
       "      <td>361.824934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328823</td>\n",
       "      <td>0.099469</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>1.389332</td>\n",
       "      <td>0.099470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept         x         z           v  np.exp(x)  I(v ** 2 + z)\n",
       "0        1.0 -1.611418 -1.566192   15.613483   0.199604     242.214667\n",
       "1        1.0 -0.080909  0.085959   42.720111   0.922278    1825.093814\n",
       "2        1.0  0.297531  0.142110    3.530885   1.346531      12.609259\n",
       "3        1.0  1.412771  1.734809  -57.235945   4.107323    3277.688187\n",
       "4        1.0  0.204214 -0.302335   -0.074792   1.226561      -0.296741\n",
       "5        1.0  1.515413  2.075660  -74.190590   4.551301    5506.319245\n",
       "6        1.0 -1.122694 -1.001452 -115.449743   0.325402   13327.641761\n",
       "7        1.0  1.490410  1.406678  203.717128   4.438913   41502.075078\n",
       "8        1.0  1.076719  0.961474   18.996406   2.935033     361.824934\n",
       "9        1.0  0.328823  0.099469    0.001091   1.389332       0.099470"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets keep x and z closely related (height and weight)\n",
    "x, z = np.random.multivariate_normal([0,0], [[var_x,r],[r,var_z]], n).T\n",
    "#blood presure\n",
    "v = np.random.normal(0,var_v,n)**3\n",
    "\n",
    "#create a pandas dataframe (easily parseable object for manipulation)\n",
    "A = pd.DataFrame({'x' : x, 'z' : z, 'v' : v})\n",
    "\n",
    "A['log_odds'] = sigmoid(A[['x','z','v']].dot([beta_x,beta_z,beta_v]) + sigma*np.random.normal(0,1,n))\n",
    "\n",
    "A['y'] = [np.random.binomial(1,p) for p in A.log_odds]\n",
    "\n",
    "#create a dataframe that encompasses our input data, model formula, and outputs\n",
    "y, X = dmatrices(formula, A, return_type='dataframe')\n",
    "\n",
    "#print it\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like dividing by zero (Wtff omgggggg universe collapses)\n",
    "def catch_singularity(f):\n",
    "    '''Silences LinAlg Errors and throws a warning instead.'''\n",
    "    \n",
    "    def silencer(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except np.linalg.LinAlgError:\n",
    "            warnings.warn('Algorithm terminated - singular Hessian!')\n",
    "            return args[0]\n",
    "    return silencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@catch_singularity\n",
    "def newton_step(curr, X, lam=None):\n",
    "    '''One naive step of Newton's Method'''\n",
    "    \n",
    "    #how to compute inverse? http://www.mathwarehouse.com/algebra/matrix/images/square-matrix/inverse-matrix.gif\n",
    "    \n",
    "    ## compute necessary objects\n",
    "    #create probability matrix, miniminum 2 dimensions, tranpose (flip it)\n",
    "    p = np.array(sigmoid(X.dot(curr[:,0])), ndmin=2).T\n",
    "    #create weight matrix from it\n",
    "    W = np.diag((p*(1-p))[:,0])\n",
    "    #derive the hessian \n",
    "    hessian = X.T.dot(W).dot(X)\n",
    "    #derive the gradient\n",
    "    grad = X.T.dot(y-p)\n",
    "    \n",
    "    ## regularization step (avoiding overfitting)\n",
    "    if lam:\n",
    "        # Return the least-squares solution to a linear matrix equation\n",
    "        step, *_ = np.linalg.lstsq(hessian + lam*np.eye(curr.shape[0]), grad)\n",
    "    else:\n",
    "        step, *_ = np.linalg.lstsq(hessian, grad)\n",
    "        \n",
    "    ## update our \n",
    "    beta = curr + step\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@catch_singularity\n",
    "def alt_newton_step(curr, X, lam=None):\n",
    "    '''One naive step of Newton's Method'''\n",
    "    \n",
    "    ## compute necessary objects\n",
    "    p = np.array(sigmoid(X.dot(curr[:,0])), ndmin=2).T\n",
    "    W = np.diag((p*(1-p))[:,0])\n",
    "    hessian = X.T.dot(W).dot(X)\n",
    "    grad = X.T.dot(y-p)\n",
    "    \n",
    "    ## regularization\n",
    "    if lam:\n",
    "        #Compute the inverse of a matrix.\n",
    "        step = np.dot(np.linalg.inv(hessian + lam*np.eye(curr.shape[0])), grad)\n",
    "    else:\n",
    "        step = np.dot(np.linalg.inv(hessian), grad)\n",
    "        \n",
    "    ## update our weights\n",
    "    beta = curr + step\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coefs_convergence(beta_old, beta_new, tol, iters):\n",
    "    '''Checks whether the coefficients have converged in the l-infinity norm.\n",
    "    Returns True if they have converged, False otherwise.'''\n",
    "    #calculate the change in the coefficients\n",
    "    coef_change = np.abs(beta_old - beta_new)\n",
    "    \n",
    "    #if change hasn't reached the threshold and we have more iterations to go, keep training\n",
    "    return not (np.any(coef_change>tol) & (iters < max_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Lab--------------\\ANACONDA\\envs\\iaml\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "F:\\Lab--------------\\ANACONDA\\envs\\iaml\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 19\n",
      "Beta : [[-5.58928293e+29]\n",
      " [ 3.96518591e+29]\n",
      " [-5.59643891e+29]\n",
      " [ 7.82353775e+29]\n",
      " [-3.42536159e+27]\n",
      " [ 7.99790190e+29]]\n"
     ]
    }
   ],
   "source": [
    "## initial conditions\n",
    "#initial coefficients (weight values), 2 copies, we'll update one\n",
    "beta_old, beta = np.ones((len(X.columns),1)), np.zeros((len(X.columns),1))\n",
    "\n",
    "#num iterations we've done so far\n",
    "iter_count = 0\n",
    "#have we reached convergence?\n",
    "coefs_converged = False\n",
    "\n",
    "#if we haven't reached convergence... (training step)\n",
    "while not coefs_converged:\n",
    "    \n",
    "    #set the old coefficients to our current\n",
    "    beta_old = beta\n",
    "    #perform a single step of newton's optimization on our data, set our updated beta values\n",
    "    beta = newton_step(beta, X, lam=lam)\n",
    "    #increment the number of iterations\n",
    "    iter_count += 1\n",
    "    \n",
    "    #check for convergence between our old and new beta values\n",
    "    coefs_converged = check_coefs_convergence(beta_old, beta, tol, iter_count)\n",
    "    \n",
    "print('Iterations : {}'.format(iter_count))\n",
    "print('Beta : {}'.format(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
